{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eswarpeddinti98/newproject/blob/main/Flower_Classification_CNN_(1)_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOYyBiG8Bb11"
      },
      "source": [
        "# **Submission Guidelines:**\n",
        "\n",
        "\n",
        "*   Once you are done with the examination please, File -> Download .ipynb\n",
        "*   Add your full name to the file name: Firstname_Lastname.ipynb\n",
        "*   Upload the .ipynb file to Moodle.\n",
        "\n",
        "# **Examination Starts Here:**\n",
        "\n",
        "## Data Download (5 points)\n",
        "*   Check the current tensorflow version\n",
        "*   Download data from this URL: https://storage.googleapis.com/srh-dataset/flower-classification/flower.zip\n",
        "*   Unzip the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f5Z_jqIlNLup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348681fb-3185-4f2a-d5f8-6ddb0e06cb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/flower.zip, /content/drive/MyDrive/flower.zip.zip or /content/drive/MyDrive/flower.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/flower.zip -d /content/drive/MyDrive/temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RG7_ETVA9w75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dcac6fe-018f-4014-ba09-6f2606b2463a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n",
            "--2024-12-16 08:21:25--  https://storage.googleapis.com/srh-dataset/flower-classification/flower.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.118.207, 74.125.200.207, 74.125.130.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.118.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-12-16 08:21:25 ERROR 404: Not Found.\n",
            "\n",
            "unzip:  cannot find or open flower.zip, flower.zip.zip or flower.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# prompt: Check the current tensorflow version\n",
        "# Download data from this URL: https://storage.googleapis.com/srh-dataset/flower-classification/flower.zip\n",
        "# Unzip the data\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "!wget https://storage.googleapis.com/srh-dataset/flower-classification/flower.zip\n",
        "!unzip flower.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziSP0i7kDBJR"
      },
      "source": [
        "## Data Preparation (10 points)\n",
        "*   Set image at an appropriate size to maximize the accuracy while fitting into the memory\n",
        "*   Load train and validation dataset\n",
        "*   Print the classes' name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "cE3VGjEPM3ne",
        "outputId": "a8ea56fc-9c46-4fb7-9f74-b9186de53a00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Could not find directory flower_photos",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b89e4d33b40c>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mBUFFER_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m X_train_ = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m'flower_photos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inferred'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory flower_photos"
          ]
        }
      ],
      "source": [
        "# prompt: Set image at an appropriate size to maximize the accuracy while fitting into the memory\n",
        "# Load train and validation dataset\n",
        "# Print the classes' name\n",
        "\n",
        "import tensorflow as tf\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "image_size = (IMG_WIDTH, IMG_HEIGHT)\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = tf.data.AUTOTUNE\n",
        "\n",
        "X_train_ = tf.keras.utils.image_dataset_from_directory(\n",
        "    'flower_photos',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size=image_size,\n",
        "    interpolation='nearest',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "X_valid_ = tf.keras.utils.image_dataset_from_directory(\n",
        "    'flower_photos',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size=image_size,\n",
        "    interpolation='nearest',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "class_names = X_train_.class_names\n",
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jCe7pQTEFNl"
      },
      "source": [
        "## Data Visualization (5 points)\n",
        "Display some of the training images along with their label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO0c4qyfM6_m"
      },
      "outputs": [],
      "source": [
        "# prompt: Display some of the training images along with their label\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in X_train_.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i].numpy().argmax()])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2xGyYiAETXX"
      },
      "source": [
        "## Model Design (25 points)\n",
        "Design a Convolutional Neural Network to solve the image classification problem. Following are the configuration for the Convolutional Neural Network:\n",
        "\n",
        "====== *Block #1 (4 points)* ======\n",
        "\n",
        "**Input Layer:**\n",
        "1. Define an input layer with an appropriate dimension\n",
        "\n",
        "**Data Augumentation:**\n",
        "1. Define some augumentation layers\n",
        "\n",
        "====== *Block #2 (5 points)* ======\n",
        "\n",
        "**Convolutional Layer #1:**\n",
        "1. Define a \"normal\" convolutional layer for images\n",
        "2. There should be **96** filters\n",
        "3. The filter size must be 11x11 and stride 4x4\n",
        "4. There should be no padding\n",
        "5. The non-linearity should be ReLU\n",
        "\n",
        "**Normalization Layer #1:**\n",
        "1. Define a Batch Normalization layer\n",
        "\n",
        "**Pooling Layer #1:**\n",
        "1. Define a maximum based pooling layer\n",
        "2. The pooling size should be 3x3 and stride 2x2\n",
        "\n",
        "====== *Block #3 (4 points)* ======\n",
        "\n",
        "**Convolutional Layer #2:**\n",
        "1. Define a \"normal\" convolutional layer for images\n",
        "2. There should be **256** filters\n",
        "3. The filter size must be 5x5 and stride 1x1\n",
        "4. There should be padding\n",
        "5. The non-linearity should be ReLU\n",
        "\n",
        "**Normalization Layer #2:**\n",
        "1. Define a Batch Normalization layer\n",
        "\n",
        "**Pooling Layer #2:**\n",
        "1. Define a maximum based pooling layer\n",
        "2. The pooling size should be 3x3 and stride 2x2\n",
        "\n",
        "====== *Block #4 (4 points)* ======\n",
        "\n",
        "**Convolutional Layer #3:**\n",
        "1. Define a \"normal\" convolutional layer for images\n",
        "2. There should be **384** filters\n",
        "3. The filter size must be 3x3 and stride 1x1\n",
        "4. There should be padding\n",
        "5. The non-linearity should be ReLU\n",
        "\n",
        "**Normalization Layer #3:**\n",
        "1. Define a Batch Normalization layer\n",
        "\n",
        "====== *Block #5 (4 points)* ======\n",
        "\n",
        "**Convolutional Layer #4:**\n",
        "1. Define a \"normal\" convolutional layer for images\n",
        "2. There should be **256** filters\n",
        "3. The filter size must be 3x3 and stride 1x1\n",
        "4. There should be padding\n",
        "5. The non-linearity should be ReLU\n",
        "\n",
        "**Normalization Layer #4:**\n",
        "1. Define a Batch Normalization layer\n",
        "\n",
        "**Pooling Layer #4:**\n",
        "1. Define a maximum based pooling layer\n",
        "2. The pooling size should be 3x3 and stride 2x2\n",
        "\n",
        "====== *Block #6 (4 points)* ======\n",
        "\n",
        "**Flattening:**\n",
        "1. Convert tensors into vectors\n",
        "\n",
        "**Fully connected Layer:**\n",
        "1. Define a fully connected layer with 4096 nodes and ReLU activation\n",
        "\n",
        "**Regularization Layer:**\n",
        "1. Define a Dropout layer\n",
        "2. The dropout rate should be 0.5\n",
        "\n",
        "**Output Layer:**\n",
        "1. Define an output layer\n",
        "2. Activation for the relative task"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Block #1: Input Layer and Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "input_layer = tf.keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "x = data_augmentation(input_layer)\n",
        "\n",
        "\n",
        "# Block #2: Convolutional Layer #1, Normalization Layer #1, Pooling Layer #1\n",
        "x = tf.keras.layers.Conv2D(96, (11, 11), strides=(4, 4), padding='valid', activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "\n",
        "# Block #3: Convolutional Layer #2, Normalization Layer #2, Pooling Layer #2\n",
        "x = tf.keras.layers.Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "\n",
        "# Block #4: Convolutional Layer #3, Normalization Layer #3\n",
        "x = tf.keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# Block #5: Convolutional Layer #4, Normalization Layer #4, Pooling Layer #4\n",
        "x = tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "\n",
        "# Block #6: Flattening, Fully connected Layer, Regularization Layer, Output Layer\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "output_layer = tf.keras.layers.Dense(len(class_names), activation='softmax')(x) # Output layer with softmax\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "00ot685njDTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4NVedFoK8OA"
      },
      "source": [
        "## Model Compiling (5 points)\n",
        "1.   Choose an optimizer\n",
        "2.   Choose an appropriate loss function\n",
        "3.   The metric should be accuracy\n",
        "4.   Print the model's summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hJPjU3qNCwg"
      },
      "outputs": [],
      "source": [
        "# prompt: Choose an optimizer\n",
        "# Choose an appropriate loss function\n",
        "# The metric should be accuracy\n",
        "# Print the model's summary\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARQdpgEkEnXo"
      },
      "source": [
        "## Callback (5 points)\n",
        "Define callback functions for:\n",
        "*   Early Stopping\n",
        "*   Learning Rate Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFjQH3qoNE3O"
      },
      "outputs": [],
      "source": [
        "# prompt: Define callback functions for:\n",
        "# Early Stopping\n",
        "# Learning Rate Reduction\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PatgNkrSEw78"
      },
      "source": [
        "## Model Training (5 points)\n",
        "Train the model for 15 epochs with callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyppKqgqNGJC"
      },
      "outputs": [],
      "source": [
        "# prompt: Train the model for 15 epochs with callbacks\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_,\n",
        "    validation_data=X_valid_,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKehT3WAFOF3"
      },
      "source": [
        "## Training Visualization (5 points)\n",
        "Plot training history with training and validation's loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Plot training history with training and validation's loss and accuracy\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ayZYVKxEjSnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxWMZ2CQ1Wa_"
      },
      "source": [
        "## Transfer Learning (20 points)\n",
        "1. Choose an appropriate pre-trained model without the top (last) layers\n",
        "2. Rebuild the last layers with GlobalAveragePooling -> BatchNormalization -> Dropout -> Output\n",
        "3. Freeze the pretrained weights & unfreeze the added layers\n",
        "4. Choose an optimizer and an appropriate loss function\n",
        "5. Print the model's summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Choose a pre-trained model (e.g., MobileNetV2) without the top layers\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_WIDTH, IMG_HEIGHT, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "# Freeze the base model's layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Rebuild the top layers\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "output_layer = tf.keras.layers.Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "transfer_model = tf.keras.Model(inputs=base_model.input, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "transfer_model.compile(optimizer='adam',\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Print the model's summary\n",
        "transfer_model.summary()"
      ],
      "metadata": {
        "id": "g0G895IfjZBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmklcdhW1WbA"
      },
      "source": [
        "## Fine-turning Model (5 points)\n",
        "Fine-turn the model for 15 epochs with callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i82Blm81WbA"
      },
      "outputs": [],
      "source": [
        "# prompt: Fine-turn the model for 15 epochs with callbacks\n",
        "\n",
        "history_transfer = transfer_model.fit(\n",
        "    X_train_,\n",
        "    validation_data=X_valid_,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMImtPJ0FgW2"
      },
      "source": [
        "## Confusion Matrix (5 points)\n",
        "Draw a confusion matrix for the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Draw a confusion matrix for the validation dataset\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict the labels for the validation set\n",
        "y_pred = np.argmax(model.predict(X_valid_), axis=1)\n",
        "\n",
        "# Get the true labels for the validation set\n",
        "y_true = []\n",
        "for _, labels in X_valid_:\n",
        "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot the confusion matrix using seaborn\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JcrfK8YnjhvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_xM_IwXF_o4"
      },
      "source": [
        "## Result Preview (5 points)\n",
        "Display some of the images in the validation dataset along with their prediction's label and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPkfD_uwNJtL"
      },
      "outputs": [],
      "source": [
        "# prompt: Display some of the images in the validation dataset along with their prediction's label and accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_valid_ is your validation dataset and model is your trained model\n",
        "# Replace with your actual validation data and model\n",
        "\n",
        "# Predict probabilities for validation images\n",
        "predictions = model.predict(X_valid_)\n",
        "\n",
        "# Get predicted labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "true_labels = []\n",
        "for _, labels in X_valid_:\n",
        "    true_labels.extend(np.argmax(labels.numpy(), axis=1))\n",
        "\n",
        "# Display some images with predictions and accuracy\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9): # Display 9 images\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  for images, labels in X_valid_.take(1):\n",
        "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "      predicted_class = class_names[predicted_labels[i]]\n",
        "      true_class = class_names[true_labels[i]]\n",
        "      accuracy = 1 if predicted_labels[i] == true_labels[i] else 0 # Simple accuracy calculation\n",
        "      plt.title(f\"Pred: {predicted_class} \\nTrue: {true_class} \\nAcc:{accuracy}\")\n",
        "      plt.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}